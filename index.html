<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <link href='https://fonts.googleapis.com/css?family=Architects+Daughter' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen" />
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print" />

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <title>Jmicrobenchs by M-jerez</title>
  </head>

  <body>
    <header>
      <div class="inner">
        <h1>Jmicrobenchs</h1>
        <h2>Java micro-benchmarks made easy.</h2>
        <a href="https://github.com/M-jerez/JMicrobenchs" class="button"><small>View project on</small>GitHub</a>
      </div>
    </header>

    <div id="content-wrapper">
      <div class="inner clearfix">
        <section id="main-content">
          <h3>What is this library for.</h3>

<p>This API is intended for make micro-benchmarks in java and generate nice html reports using <a href="http://www.highcharts.com/">HighChars.com</a>. It doesn't provide advanced profile functions, abnormal data detection or any other. <em>The main objective was to create a library for generate nice reports showing the performance's chart and the executed code at the same time,</em> leaving to the programmer the responsibility of the benchmark's reliability.</p>

<p>Sample report: <em>this is an just an image, the real report is generated in html. <a href="http://m-jerez.github.com/JMicrobenchs/">demos web page.</a></em></p>

<p><img src="https://raw.github.com/M-jerez/JMicrobenchs/master/media/report-sample.png" alt="Jmicrobech sample report"></p>

<h3>What's a micro-benchmark.</h3>

<p>A micro-benchmark measures and compares the time performance of code portions, this can be useful to make a general image of the code performance, to find bottlenecks on it or unusual slow behavior, nevertheless micro-benchmarks are not intended for software profiling. </p>

<p>To get more info about micro-benchmarks can read the following docs:</p>

<ul>
<li><a href="https://code.google.com/p/caliper/wiki/JavaMicrobenchmarks">Caliper micro-benchmarks.</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-benchmark1/index.html">Robust benchmarking by Brent Boyer at ibm.</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-jtp02225/index.html">Anatomy of a flawed microbenchmark by Brian Goetz at ibm.</a></li>
<li>
<a href="https://wikis.oracle.com/display/HotSpotInternals/MicroBenchmarks">Benchmark tips, oracle HotSpot documentation.</a> </li>
</ul><h3>Benchmark phases.</h3>

<p>Each benchmark consist of three different phases while the code is executed a number times.</p>

<ul>
<li>
<strong>Loading:</strong> This is the first phase and is executed only once. It shows useful results only when the program is being rung by the first time and java must load all classes. This phase is intended to measure cold start performance.</li>
<li>
<strong>Warmup:</strong> This phase must be executed many times to let the JVM make some code optimization, <a href="http://en.wikipedia.org/wiki/Just-in-time_compilation">JIT compile</a>, garbage collection, etc... During this phase the performance is not measured and will not generate any report.</li>
<li>
<strong>Profiling:</strong> This is the main phase and it doesn't must be executed many times but enough to calculate a reliable average. Execute this phase more than required could leave to incorrect results as garbage collection or other processes can distort this results.<br>
</li>
</ul><h2>Show me the code.</h2>

<h3>Write the code.</h3>

<p>Implement <code>JMicrobench</code> and put the code you want to profile inside the the <code>runBech()</code> method. To profile one portion of code create a <code>TimeProfiler</code> object and call it's function <code>startCount()</code> and <code>stopCount</code>.</p>

<div class="highlight"><pre> <span class="kd">public</span> <span class="kd">class</span> <span class="nc">FirstTest</span> <span class="kd">implements</span> <span class="n">JMicrobench</span> <span class="o">{</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">runBench</span><span class="o">()</span> <span class="o">{</span>
        <span class="n">String</span> <span class="n">t1</span> <span class="o">=</span> <span class="s">"void"</span><span class="o">,</span> <span class="n">t2</span> <span class="o">=</span> <span class="s">"create HashMap"</span><span class="o">,</span> <span class="n">t3</span> <span class="o">=</span> <span class="s">"HashMap put"</span><span class="o">;</span>

        <span class="n">TimeProfiler</span> <span class="n">tp</span> <span class="o">=</span> <span class="n">Registry</span><span class="o">.</span><span class="na">getTimeProfiler</span><span class="o">(</span><span class="s">"FirstTest Performance"</span><span class="o">);</span>

        <span class="n">tp</span><span class="o">.</span><span class="na">startCount</span><span class="o">(</span><span class="n">t1</span><span class="o">);</span>
        <span class="cm">/* Nothing Executed here */</span>
        <span class="cm">/* time consumed by startCount() &amp; stopCount() */</span>
        <span class="n">tp</span><span class="o">.</span><span class="na">stopCount</span><span class="o">(</span><span class="n">t1</span><span class="o">);</span>

        <span class="cm">/* Measures the time required to create a HashMap. */</span>
        <span class="n">tp</span><span class="o">.</span><span class="na">startCount</span><span class="o">(</span><span class="n">t2</span><span class="o">);</span>
        <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;</span> <span class="n">h</span> <span class="o">=</span> <span class="k">new</span> <span class="n">HashMap</span><span class="o">&lt;</span><span class="n">String</span><span class="o">,</span> <span class="n">String</span><span class="o">&gt;();</span>
        <span class="n">tp</span><span class="o">.</span><span class="na">stopCount</span><span class="o">(</span><span class="n">t2</span><span class="o">);</span>

        <span class="cm">/* Measures the time required for the put operation */</span>
        <span class="n">tp</span><span class="o">.</span><span class="na">startCount</span><span class="o">(</span><span class="n">t3</span><span class="o">);</span>
        <span class="n">h</span><span class="o">.</span><span class="na">put</span><span class="o">(</span><span class="s">"hello"</span><span class="o">,</span> <span class="s">"world"</span><span class="o">);</span>
        <span class="n">tp</span><span class="o">.</span><span class="na">stopCount</span><span class="o">(</span><span class="n">t3</span><span class="o">);</span>   
    <span class="o">}</span>
<span class="o">}</span>
</pre></div>

<p>As you can see it is not possible to create a <code>TimeProfiler</code> directly, all TimeProfilers are created/accessed in a static way through the <code>Registry</code> class, this class is basically a Map of TimeProfilers objects identified by it's title. This behavior allows to access the same <code>TimeProfiler</code> in any point of the executed program. </p>

<p>As you can also see one of it's drawbacks is that write this kind of benchmark is too verbose, but this allows to make accurate measures, nested calls etc...</p>

<h3>Run the benchmark.</h3>

<p>Create a new instance of your test class, in this case <code>FirstTest</code>; create a new <code>BenchmarkRunner</code> and run it <code>run()</code>;  finally create one of the available <code>Reports</code> and write to File or Output.</p>

<div class="highlight"><pre>    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="o">{</span>        
        <span class="kt">int</span> <span class="n">profileLoops</span> <span class="o">=</span> <span class="mi">50</span><span class="o">;</span>
        <span class="kt">int</span> <span class="n">warmupLoops</span> <span class="o">=</span> <span class="n">profileLoops</span> <span class="o">*</span> <span class="mi">1000</span><span class="o">;</span>

        <span class="n">FirstTest</span> <span class="n">firstTest</span> <span class="o">=</span> <span class="k">new</span> <span class="n">FirstTest</span><span class="o">();</span>

        <span class="cm">/* create &amp; run the benchmark */</span>
        <span class="k">new</span> <span class="nf">BenchmarkRunner</span><span class="o">(</span><span class="n">warmupLoops</span><span class="o">,</span> <span class="n">profileLoops</span><span class="o">,</span><span class="n">firstTest</span><span class="o">).</span><span class="na">run</span><span class="o">();</span>

        <span class="cm">/* generate the report &amp; write to file */</span>   
        <span class="n">ReportOptions</span> <span class="n">options</span> <span class="o">=</span> <span class="k">new</span>  <span class="n">ReportOptions</span><span class="o">(</span><span class="s">"../test/"</span><span class="o">);</span>
        <span class="k">new</span> <span class="nf">FullWebReport</span><span class="o">(</span><span class="n">options</span><span class="o">).</span><span class="na">writeFullWebToFile</span><span class="o">(</span><span class="s">"C:/Users/mjerez/Desktop/report.html"</span><span class="o">);</span>

    <span class="o">}</span>
</pre></div>

<p>The <code>RenderOptions</code> object is required to configure the generated report, in this case we only have set the relative path were are the java source files. if the source files ".java" and the executables ".class" are in the same directories this path is a void string -&gt; "". To see more options go to <a href="http://m-jerez.github.com/JMicrobenchs/doc/mjerez/jmicrobench/reports/ReportOptions.html">javadoc.</a></p>

<h3>Watch results.</h3>

<p>The next image is a snapshot of the html generated from the previous code. One report like this will be generated for each <code>TimeProfiler</code> object created during the benchmark execution.</p>

<p><img src="https://raw.github.com/M-jerez/JMicrobenchs/master/media/report-FirstTest.png" alt="FirstTest Jmicrobech report"></p>

<h3>Where to find more info.</h3>

<ul>
<li><a href="http://m-jerez.github.com/JMicrobenchs/">JMicrobech web page.</a></li>
<li><a href="http://m-jerez.github.com/JMicrobenchs/doc/">Javadoc.</a></li>
</ul>
        </section>

        <aside id="sidebar">
          <a href="https://github.com/M-jerez/JMicrobenchs/zipball/master" class="button">
            <small>Download</small>
            .zip file
          </a>
          <a href="https://github.com/M-jerez/JMicrobenchs/tarball/master" class="button">
            <small>Download</small>
            .tar.gz file
          </a>

          <p class="repo-owner"><a href="https://github.com/M-jerez/JMicrobenchs"></a> is maintained by <a href="https://github.com/M-jerez">M-jerez</a>.</p>

          <p>This page was generated by <a href="pages.github.com">GitHub Pages</a> using the Architect theme by <a href="http://twitter.com/jasonlong">Jason Long</a>.</p>
        </aside>
      </div>
    </div>

  
  </body>
</html>